{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8cf3a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a36d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (4.52.3)\n",
      "Requirement already satisfied: librosa in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: jiwer in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (0.32.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from jiwer) (8.2.1)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from jiwer) (3.13.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from click>=8.1.8->jiwer) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\envs\\finetuning\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# You can run this in terminal OR create a setup script\n",
    "!pip install  datasets transformers librosa jiwer evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a5303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\finetuning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainer, TrainingArguments, Trainer\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a2990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 244\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Audio\n",
    "\n",
    "def load_local_dataset(audio_dir, transcription_dir):\n",
    "    audio_files = sorted([f for f in os.listdir(audio_dir) if f.endswith('.mp3')])\n",
    "    transcription_files = sorted([f for f in os.listdir(transcription_dir) if f.endswith('.txt')])\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        base_name = os.path.splitext(audio_file)[0]\n",
    "        txt_file = base_name + \".txt\"\n",
    "        \n",
    "        audio_path = os.path.join(audio_dir, audio_file)\n",
    "        transcription_path = os.path.join(transcription_dir, txt_file)\n",
    "\n",
    "        if os.path.exists(transcription_path):\n",
    "            with open(transcription_path, 'r', encoding='utf-8') as f:\n",
    "                transcription = f.read().strip()\n",
    "            dataset.append({\n",
    "                \"audio\": audio_path,\n",
    "                \"sentence\": transcription\n",
    "            })\n",
    "\n",
    "    return Dataset.from_list(dataset)\n",
    "\n",
    "# Load your train dataset\n",
    "train_audio_dir = r\"C:\\Users\\ASUS\\Desktop\\Whispher-Finetuning\\sindhi_data\\sindhi_data\\audio\"\n",
    "train_text_dir = r\"C:\\Users\\ASUS\\Desktop\\Whispher-Finetuning\\sindhi_data\\sindhi_data\\transcriptions\"\n",
    "train_dataset = load_local_dataset(train_audio_dir, train_text_dir)\n",
    "\n",
    "# Preprocess: convert to Audio column with sampling_rate\n",
    "train_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "print(\"Training samples:\", len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd342b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 384)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 384, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 384)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=384, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# Load Whisper Tiny instead of Whisper Base\n",
    "model_name = \"openai/whisper-tiny\"  # This is the correct model for Whisper Tiny\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# model_name = \"openai/whisper-base\"\n",
    "\n",
    "# processor = WhisperProcessor.from_pretrained(model_name)\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# # Move to GPU if available\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bbe01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 244/244 [00:06<00:00, 39.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # Audio -> log-Mel features\n",
    "    batch[\"input_features\"] = processor(\n",
    "        audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_tensors=\"pt\",\n",
    "        language=\"sd\",\n",
    "        task=\"transcribe\"\n",
    "    ).input_features[0]\n",
    "\n",
    "    # Transcription -> tokenized labels\n",
    "    batch[\"labels\"] = processor.tokenizer(\n",
    "        batch[\"sentence\"],\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids[0]\n",
    "\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_dataset, remove_columns=train_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463db78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        batch = processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "        labels_batch = processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10090b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27284\\1665441860.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 04:01, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.456500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.264800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.556600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.457100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.353100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.336100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.204900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.211400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.174900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.076700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.049600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\finetuning\\lib\\site-packages\\transformers\\modeling_utils.py:3464: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=r\"C:\\Users\\ASUS\\Desktop\\whispher-tiny\\input\",\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.005,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=2,\n",
    "    save_total_limit=2,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,  # using train as eval for now\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"🚀 Starting fine-tuning...\")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# Save the model & processor\n",
    "save_path = r\"C:\\Users\\ASUS\\Desktop\\whispher-tiny\\output\"\n",
    "trainer.save_model(save_path)\n",
    "processor.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400e59c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 common_voice_sd_41397153.mp3 | WER: 0.4375\n",
      "   REF: ڇا اهو اسان کي ٻڌائي ٿو ته آمريڪي واپاري قانون ڪم ڪري رهيو آهي، هن چيو\n",
      "   HYP:  چان اهو اسان کي اڌائي ٿو ته عمريقي، پاپاري ڪاملون ڪم ڪري رهيو آهي، نه ٿيو \n",
      "\n",
      "📄 common_voice_sd_41397158.mp3 | WER: 0.7500\n",
      "   REF: بخاري جي ٻين روايتن مان معلوم ٿئي ٿو\n",
      "   HYP:  ٻو خاري جي بيٽن روائيٽن مان، معلوم ٿئي ٿو. \n",
      "\n",
      "📄 common_voice_sd_41397194.mp3 | WER: 0.4000\n",
      "   REF: ڇهين مالا پيدا ٿئي ٿي\n",
      "   HYP:  چهن مالا پيدا ٿئيٽيءَ ٿي \n",
      "\n",
      "📄 common_voice_sd_41397195.mp3 | WER: 0.5789\n",
      "   REF: يقينن، ان جو مطلب اهو نه وٺڻ گهرجي ته هتي ڪي به مسئلا ۽ محروم طبقن جي کوٽ ناهي.\n",
      "   HYP:  اهڪينن اڻهن اڄهن جو مطلب اهو نه وٺڻ گھرجي هٽي هٽي ڪي به مسلاح ۽ محرون تبقن جي خو تناحي \n",
      "\n",
      "📄 common_voice_sd_41397199.mp3 | WER: 0.5000\n",
      "   REF: تنهن ڪري، انهن ۾ صالح آهن\n",
      "   HYP:  تهن ڪري انهن ۾ سالي آهن \n",
      "\n",
      "📄 common_voice_sd_41397200.mp3 | WER: 1.0000\n",
      "   REF: اهي حالتون تڏهن هيون.\n",
      "   HYP:  کئي حالتو تڏي هئيون. \n",
      "\n",
      "📄 common_voice_sd_41397487.mp3 | WER: 0.8889\n",
      "   REF: حمائمه ملڪ به وومين پروٽيڪشن بل جي حامي آهي\n",
      "   HYP:  هم ائي وان ملڪ به ومنهن پڙيشن بل جي هان ۾ آهي. \n",
      "\n",
      "📄 common_voice_sd_41397489.mp3 | WER: 0.4706\n",
      "   REF: توهان جي سادگي ۽ توهان جي والدين سان توهان جي شفقت ڏسي مان ڏاڍو متاثر ٿيو آهيان\n",
      "   HYP:  توهان جي ساتگي ۽ توهان جي واڳائن سان توهان جي شفڪترسي واريا ڏو مٿاس چو آهيان \n",
      "\n",
      "📄 common_voice_sd_41397523.mp3 | WER: 0.7500\n",
      "   REF: احد چيما کي وٺو.\n",
      "   HYP:  اهڙ ٽيمان کي مٿو \n",
      "\n",
      "📄 common_voice_sd_41421602.mp3 | WER: 0.8333\n",
      "   REF: خشونت سنگهه علامه اقبال جي ڪلام جو انگريزيءَ ۾ ترجمو ڪيو آهي.\n",
      "   HYP:  هشونهٽ سنگ عرام مائقبار جي خلام جو، جو انگريزي ۾ تجمعون پيو آهي \n",
      "\n",
      "📄 common_voice_sd_41421678.mp3 | WER: 0.4000\n",
      "   REF: هي انهن مان هڪ آهي.\n",
      "   HYP:  هي انهن وان هڪ آهي \n",
      "\n",
      "📄 common_voice_sd_41421686.mp3 | WER: 0.4706\n",
      "   REF: مون عادت جي خلاف سينٽرل لاڪ کوليو ۽ کيس سامهون واري سيٽ تي ويهڻ جو اشارو ڪيو\n",
      "   HYP:  ٻون عادت لي کلاف سنينٽرلوڪ کوليو ۽ کيس سامهون واري سيٽت تي ويهن جو شارو ڪيو \n",
      "\n",
      "📄 common_voice_sd_41421762.mp3 | WER: 1.4000\n",
      "   REF: پاڙيسرين سان پرامن زندگي گذاريو\n",
      "   HYP: پاري سرين سان پر امن زن تقي گذاريو. \n",
      "\n",
      "📄 common_voice_sd_41421798.mp3 | WER: 0.6000\n",
      "   REF: ڪڏهن ڇوڪرين کي گوليون هڻي زنده دفن ڪيو ويندو آهي\n",
      "   HYP: ڪڏهن چونڪرين کي ٻوليون هني جندا دفن ڪيون ويدو آهي \n",
      "\n",
      "📄 common_voice_sd_41421807.mp3 | WER: 0.7500\n",
      "   REF: اها صلاحيت پنهنجي عروج تي نظر اچي ٿي\n",
      "   HYP:  يا سرائي تپنجي ارون جتي نظر اچيئن ٿي \n",
      "\n",
      "📄 common_voice_sd_41421870.mp3 | WER: 0.3750\n",
      "   REF: هن سوچ کي تبديل ڪرڻ جي ضرورت آهي.\n",
      "   HYP:  هن سوچ کي تبديل ڪڙجي ضرورت آهي \n",
      "\n",
      "📄 common_voice_sd_41425127.mp3 | WER: 0.5714\n",
      "   REF: آسٽريليا خلاف ٽي ٽوئنٽي اسڪواڊ جو اعلان ڪري ڇڏيو عامر بهير عماد جي واپسي\n",
      "   HYP:  هونسٽريليا کلاس ٽيٽنٽي اسڪوار جو اعلاد ڪري ڇڏيو آمهر بيهر عماد جي واپسي \n",
      "\n",
      "📄 common_voice_sd_41425190.mp3 | WER: 0.7778\n",
      "   REF: ايترو خوش ٿيو جو هاڻي ملاقات جا چانس وڌندا.\n",
      "   HYP:  هيترو خوش ٿيو جو هالي ملاڪت جا چان سو وڌ ما \n",
      "\n",
      "📄 common_voice_sd_41425208.mp3 | WER: 0.5000\n",
      "   REF: مون کي اها جرئت نه هئي ته کيس اها خراب خبر ٻڌايان\n",
      "   HYP:  مون کي اه جورت نهوءِ ته کيس اها خراب خبر ٻڌ آيان \n",
      "\n",
      "📄 common_voice_sd_41425246.mp3 | WER: 0.4286\n",
      "   REF: هن ڀيري به اسلام آباد جو مقابلو آهي، پر هن ڀيري به مقابلو آهي\n",
      "   HYP:  هن بھري به اسلام ووحد جو موقعبرو آهي، پڙهن هن بھري به موقعبرو آهي \n",
      "\n",
      "📄 common_voice_sd_41425265.mp3 | WER: 5.5455\n",
      "   REF: مان ڇا ٿو چوان ته ”اسين توکي قيامت ۾ وٺي وينداسين“.\n",
      "   HYP:  مان چان ٿو چوءَ ته اسين تو کي ڪيئن ڪيئن ڪيئن ته ڪيئن ڪيئن ڪيئن ته ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڪيئن ڏاسينهن \n",
      "\n",
      "📄 common_voice_sd_41425290.mp3 | WER: 1.0000\n",
      "   REF: ايشيا\n",
      "   HYP:  پيشيا \n",
      "\n",
      "📄 common_voice_sd_41425296.mp3 | WER: 1.0000\n",
      "   REF: مثال ڏيو.\n",
      "   HYP:  بسال ڏيو \n",
      "\n",
      "📄 common_voice_sd_41425328.mp3 | WER: 1.0000\n",
      "   REF: اها آهي سخت تنقيد.\n",
      "   HYP:  هوه آهي سڪت تنقي ده \n",
      "\n",
      "📄 common_voice_sd_41425350.mp3 | WER: 0.7727\n",
      "   REF: مون پنهنجي آخري پوسٽ ۾ چيو هو ته اسان جي ٽيم کٽي رهي آهي پر ان ۾ چيمپيئن بڻجڻ جو معيار ناهي\n",
      "   HYP:  هون پنهنجي آهنجي آهن خٽيءَ رهي آهي، پر ان ۾ چنپن ڀڄڻ جي آهن جو ميار ناهي \n",
      "\n",
      "📄 common_voice_sd_41425395.mp3 | WER: 0.5000\n",
      "   REF: ٻيو مالا پيدا ٿيو\n",
      "   HYP:  ٻيو معلو پيدا چو \n",
      "\n",
      "✅ Saved results to finetuned_whisper_sindhi_results.csv\n",
      "🔥 Average WER on test set: 0.8731\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "from evaluate import load\n",
    " \n",
    "# Load fine-tuned model and processor\n",
    "\n",
    "model_path = r\"C:\\Users\\ASUS\\Desktop\\Whispher-Finetuning\\final-model\"\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_path)\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "# Fix the generation config - remove forced_decoder_ids\n",
    "\n",
    "model.generation_config.language = \"<|sd|>\"\n",
    "\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None  # This is the key fix\n",
    " \n",
    "# Load WER metric\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    " \n",
    "# Test data paths\n",
    "\n",
    "test_audio_dir = r\"C:\\Users\\ASUS\\Desktop\\Whispher-Finetuning\\test_54\\audio\"\n",
    "\n",
    "test_text_dir = r\"C:\\Users\\ASUS\\Desktop\\Whispher-Finetuning\\test_54\\transcription\"\n",
    " \n",
    "# Files to evaluate\n",
    "\n",
    "test_files = sorted([f for f in os.listdir(test_audio_dir) if f.endswith(\".mp3\")])\n",
    " \n",
    "# Inference loop\n",
    "\n",
    "results = []\n",
    "\n",
    "total_wer = 0\n",
    " \n",
    "for audio_file in test_files:\n",
    "\n",
    "    audio_path = os.path.join(test_audio_dir, audio_file)\n",
    "\n",
    "    text_path = os.path.join(test_text_dir, audio_file.replace(\".mp3\", \".txt\"))\n",
    " \n",
    "    # Load audio\n",
    "\n",
    "    audio, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    input_features = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_features.to(model.device)\n",
    " \n",
    "    # Get reference text\n",
    "\n",
    "    with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        reference = f.read().strip().lower()\n",
    " \n",
    "    # Generate transcription with explicit generation parameters\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predicted_ids = model.generate(\n",
    "\n",
    "            input_features,\n",
    "\n",
    "            language=\"<|sd|>\",  # Sindhi language token\n",
    "\n",
    "            task=\"transcribe\",\n",
    "\n",
    "            forced_decoder_ids=None,  # Explicitly set to None\n",
    "\n",
    "            max_length=448,\n",
    "\n",
    "            num_beams=1,\n",
    "\n",
    "            do_sample=False\n",
    "\n",
    "        )\n",
    "\n",
    "    prediction = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0].lower()\n",
    " \n",
    "    # WER calculation\n",
    "\n",
    "    wer = wer_metric.compute(predictions=[prediction], references=[reference])\n",
    "\n",
    "    total_wer += wer\n",
    " \n",
    "    print(f\"📄 {audio_file} | WER: {wer:.4f}\")\n",
    "\n",
    "    print(\"   REF:\", reference)\n",
    "\n",
    "    print(\"   HYP:\", prediction, \"\\n\")\n",
    " \n",
    "    results.append({\n",
    "\n",
    "        \"File\": audio_file,\n",
    "\n",
    "        \"Reference\": reference,\n",
    "\n",
    "        \"Prediction\": prediction,\n",
    "\n",
    "        \"WER\": round(wer, 4)\n",
    "\n",
    "    })\n",
    " \n",
    "# Save to CSV\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.to_csv(\"finetuned_whisper_sindhi_results.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Saved results to finetuned_whisper_sindhi_results.csv\")\n",
    " \n",
    "# Print average WER\n",
    "\n",
    "average_wer = total_wer / len(results)\n",
    "\n",
    "print(f\"🔥 Average WER on test set: {average_wer:.4f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc588f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
